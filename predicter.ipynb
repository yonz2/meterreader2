{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MeterReader - The Predicter\n",
    "\n",
    "This notebok tests the prediction using the models trained by \"trainer.ipynb\"\n",
    "\n",
    "- Frames : Get Extract the Frame inside of the meter from the original image\n",
    "- Counter : Extract the Counter from within the frame\n",
    "- Digits: Get the value of each digit of the Counter\n",
    "\n",
    "## Training Data\n",
    "\n",
    "The training data is taken from the respective Roboflow projects. The data is annotated using either Roboflow or manually via script (Digits)\n",
    "\n",
    "## Models\n",
    "\n",
    "The are pre-trained custom models, trained by the \"trainer.ipynb script\n",
    "\n",
    "## Process\n",
    "The detation of the value of the electricity meter is done using three different model, to simplify the detection (each model is small enough to allow three t be loaded at the same time). This simplifies the algorithm, as there is hardly any image manipulation required. Inspriration comes from (OpenCV practice: OCR for the electricity meter)[https://en.kompf.de/cplus/emeocv.html]. However, the use of OCR did not give the expected results.\n",
    "\n",
    "The idea here is to \"divide and conquer\". I.e. to desect the image in three simple steps, where each step will isolate a part of the image. Each part is big enough so the model will be simple and quick.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Import the libraries and load the pretrained models used to   predict the meter values\n",
    "\n",
    "Note: The training was done on a MacMini (2024) with a M4 Processor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uses the Ultralytics YOLOv11 Libraries\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "\n",
    "from  predict_helpers import *\n",
    "\n",
    "# Check to see if running on a Mac or not (Apple Silicon)\n",
    "device_to_use = 'cpu'\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device_to_use = 'mps' # Apple Silicon\n",
    "\n",
    "print(f\"Device used for training: {device_to_use}\")\n",
    "\n",
    "# Load the three different models\n",
    "\n",
    "project_name=\"meterreader_YOLO\"\n",
    "\n",
    "run_name_frame = \"meter-frame-1\"\n",
    "run_name_counter= \"meter-counter-640-1\"\n",
    "run_name_digits = \"meter-digits-3\"\n",
    "\n",
    "model_path_digits = f\"{project_name}/{run_name_digits}/weights/best.pt\"\n",
    "model_path_frame = f\"{project_name}/{run_name_frame}/weights/best.pt\"\n",
    "model_path_counter= f\"{project_name}/{run_name_counter}/weights/best.pt\"\n",
    "\n",
    "# load the models\n",
    "model_frame = YOLO(model_path_frame) # Detect the main white frame of the electricity meter\n",
    "model_counter = YOLO(model_path_counter) # Detect the counter frame on the image\n",
    "model_digits = YOLO(model_path_digits) # Detect the value of the counter (the digits)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Detection \n",
    "\n",
    "### The Frame\n",
    "\n",
    "\n",
    "1. Extract the Frame from the image \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only needed if running inside a Jupyter Notebook\n",
    "if is_running_in_jupyter():\n",
    "    from ipyfilechooser import FileChooser\n",
    "    # Create and display a FileChooser widget to select the file to process\n",
    "    fc = FileChooser('/Users/yonz/Workspace/images')\n",
    "    display(fc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here  the image_path should be passed as an attribute to a class method / function\n",
    "#\n",
    "if  is_running_in_jupyter() and len(fc.selected) > 0:\n",
    "    image_path = fc.selected\n",
    "else:\n",
    "    image_path = \"/Users/yonz/Workspace/images/meter-frame-1/IMG_6987.jpg\" \n",
    "    \n",
    "image = load_image(image_path)\n",
    "image_size = image.shape[:2]\n",
    "print(f\"Image {image_path} Shape = {image_size} Image Dtype is: {image.dtype}\")\n",
    "plot_image(image,title=\"Original Image\", bgr=True)\n",
    "print(f\"Loading model weights from: {model_path_frame}\")\n",
    "\n",
    "# run first prediction on the image to get theframe with the counter\n",
    "results = model_frame(image, device=device_to_use, imgsz=[640,320], conf=0.4, iou=0.5,\n",
    "                        save=False, save_crop =False, save_txt=False,\n",
    "                        name=f\"{run_name_frame}/\", project=f\"{project_name}\", exist_ok=True)\n",
    "\n",
    "\n",
    "frame_image = None # initialize to None to indicate no detection\n",
    "if results[0].boxes is not None and len(results[0].boxes.xyxy) > 0:\n",
    "    boxes = results[0].boxes.xyxy  # Get the boxes directly\n",
    "    box = boxes[0] # Take the first box, as we expect only one\n",
    "    x1, y1, x2, y2 = map(int, box.tolist())\n",
    "    frame_image = image[y1:y2, x1:x2].copy()\n",
    "    plot_image(results[0].plot(), title=\"Detected Frame\", bgr=True)\n",
    "\n",
    "if frame_image is not None:\n",
    "    # Process the cropped image\n",
    "    print(f\"Frame Image Shape: {frame_image.shape}\")\n",
    "    plot_image(frame_image, title=\"Frame Image\", bgr=True)\n",
    "\n",
    "\n",
    "else:\n",
    "    print(\"No object detected in the image.\")\n",
    "\n",
    "# This functon should return the results image (with the bounding boxes), and the cropped  image counter detected\n",
    "# return results[0].plot(), frame_image  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Counter\n",
    "\n",
    "\n",
    "2. Extract the counter from the frame\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here the the crop area returned by previous function, should be passed as an attribute to a class method / function \n",
    "\n",
    "# run second prediction on the frame image to get counter itself\n",
    "results = model_counter(frame_image, device=device_to_use, imgsz=[320,320], conf=0.4, iou=0.5,\n",
    "                        save=False, save_crop =True, save_txt=False,\n",
    "                        name=f\"{run_name_counter}/\", project=f\"{project_name}\", exist_ok=True)\n",
    "\n",
    "\n",
    "counter_image = None # initialize to None to indicate no detection\n",
    "if results[0].boxes is not None and len(results[0].boxes.xyxy) > 0:\n",
    "    boxes = results[0].boxes.xyxy  # Get the boxes directly\n",
    "    box = boxes[0] # Take the first box, as we expect only one\n",
    "    x1, y1, x2, y2 = map(int, box.tolist())\n",
    "    counter_image = frame_image[y1:y2, x1:x2].copy()\n",
    "    plot_image(results[0].plot(), title=\"Detected counter\", bgr=True)\n",
    "\n",
    "\n",
    "if counter_image is not None:\n",
    "    # Process the cropped image\n",
    "    plot_image(counter_image, title=\"Counter Image\", bgr=True)\n",
    "\n",
    "    # Attemt to rotate the image so that the horizontal lines are straight,\n",
    "    # then padd that image to a fixed site, for use in a second model\n",
    "    rotation_angle = determine_rotation_angle(counter_image, horizontal_threshold=0.1)          \n",
    "    image_rotated = rotate_image(counter_image, rotation_angle)\n",
    "    plot_image(image_rotated, title=f\"Counter Image - Rotated by {rotation_angle:.3f} degrees\", bgr=True)\n",
    "    \n",
    "    # Convert the image to a simply binary (B/W) Image\n",
    "    binary_image = convert_to_binary(image_rotated, bgr=True, invert=True)\n",
    "    plot_image(binary_image, title=\"Counter Image - Binary / Inverted\")\n",
    "else:\n",
    "    print(\"No object detected in the image.\")\n",
    "\n",
    "# This functon should return the results image (with the bounding boxes), and the cropped binary image\n",
    "# return results[0].plot(), binary_image  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Digits\n",
    "\n",
    "3. Extract the digits from the counter\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here the the binary image genrated by previous function, should be passed as an attribute to a class method / function \n",
    "\n",
    "# Digit name to value mapping\n",
    "digit_name_map = {\n",
    "    \"zero\": \"0\",\n",
    "    \"one\": \"1\",\n",
    "    \"two\": \"2\",\n",
    "    \"three\": \"3\",\n",
    "    \"four\": \"4\",\n",
    "    \"five\": \"5\",\n",
    "    \"six\": \"6\",\n",
    "    \"seven\": \"7\",\n",
    "    \"eight\": \"8\",\n",
    "    \"nine\": \"9\",\n",
    "    \"ten\": \"10\", # if needed\n",
    "    \"NaN\": \"NaN\"\n",
    "}\n",
    "\n",
    "meter_value_str = \"\"\n",
    "meter_value_int = None\n",
    "\n",
    "results = model_digits(binary_image, device=device_to_use,  imgsz=[192,800], conf=0.4, iou=0.5,\n",
    "                    save=True, save_crop =True, save_txt=True,\n",
    "                    name=f\"{run_name_digits}/\", project=f\"{project_name}\", exist_ok=True)\n",
    "\n",
    "\n",
    "if results[0].boxes is not None and len(results[0].boxes.xyxy) > 0:\n",
    "    plot_image(results[0].plot(), title=\"Detected Digits\", bgr=True)\n",
    "    boxes = results[0].boxes.xyxy.tolist()  # Convert to list for easier iteration\n",
    "    class_ids = results[0].boxes.cls.tolist()\n",
    "    names = results[0].names\n",
    "\n",
    "    valid_boxes = []\n",
    "\n",
    "    for i, box in enumerate(boxes):\n",
    "        x1, y1, x2, y2 = map(int, box)\n",
    "        w = x2 - x1\n",
    "        h = y2 - y1\n",
    "        area = w * h\n",
    "\n",
    "        if h > w and area >= 200:\n",
    "            valid_boxes.append((i,x1, y1, x2, y2))\n",
    "            # print(f\"Valid Box found: Class {names[int(class_ids[i])]}, x1={x1}, y1={y1}, x2={x2}, y2={y2}, w={w}, h={h}, area={area}\")\n",
    "    \n",
    "    if valid_boxes:\n",
    "        # Sort valid boxes by x1 (reading order)\n",
    "        valid_boxes.sort(key=lambda box: box[1])  # Sort by the second element (x1)\n",
    "\n",
    "        num_digits_to_read = min(6, len(valid_boxes))\n",
    "        for digitNo in range(num_digits_to_read):\n",
    "            i, x1, y1, x2, y2 = valid_boxes[digitNo]\n",
    "            digit_name = names[int(class_ids[i])]\n",
    "            digit_value = digit_name_map.get(digit_name) # Get the digit value from the map\n",
    "            if digit_value is not None:\n",
    "                meter_value_str += digit_value\n",
    "                print(f\"Valid box label: #{digitNo+1} (x1={x1}): {digit_name} -> {digit_value}\")\n",
    "            else:\n",
    "                print(f\"Warning: Digit name '{digit_name}' not found in lookup table.\")\n",
    "                meter_value_str = None # Reset meter value since a digit could not be identified.\n",
    "                break # Stop processing since the meter value is now invalid\n",
    "\n",
    "        if meter_value_str is not None: # Only convert to int if all digits could be identified.\n",
    "            print(f\"Meter Value (str): {meter_value_str}\")\n",
    "            try:\n",
    "                meter_value_int = int(meter_value_str)\n",
    "                print(f\"Meter Value (int): {meter_value_int}\")\n",
    "            except ValueError:\n",
    "                print(f\"Could not convert Meter Value ({meter_value_str}) to int\")\n",
    "\n",
    "\n",
    "    else:\n",
    "        print(\"No valid boxes found matching the criteria.\")\n",
    "else:\n",
    "    print(\"No digits detected.\")\n",
    "\n",
    "\n",
    "# This functon should return the results image (with the bounding boxes), the string and the int values\n",
    "# return results[0].plot(), meter_value_str, meter_value_int"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
